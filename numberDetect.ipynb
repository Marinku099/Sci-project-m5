{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import imutils\n",
    "import easyocr\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"D:/coding/projectm5/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectID(path):\n",
    "    result = []\n",
    "    img = cv2.imread(path)\n",
    "    img = img[1600: , 100:500]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    bfilter = cv2.bilateralFilter(gray, 15, 30, 30)\n",
    "    edged = cv2.Canny(bfilter, 30, 200)\n",
    "    # plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    keypoint = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(keypoint)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:20]\n",
    "    \n",
    "    mask = np.zeros(gray.shape, np.uint8)\n",
    "    location = None\n",
    "\n",
    "    for contour in contours:\n",
    "        # print(i)\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        if len(approx) == 4:\n",
    "            location = approx\n",
    "            new_image = cv2.drawContours(mask, [location], 0, 255, -1)\n",
    "            new_image = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "            (x, y) = np.where(mask==255)\n",
    "            (x1, y1) = (np.min(x), np.min(y))\n",
    "            (x2, y2) = (np.max(x), np.max(y))\n",
    "            cropped_image = gray[x1:x2+1, y1:y2+1]\n",
    "\n",
    "            reader = easyocr.Reader(['en'])\n",
    "            result = reader.readtext(cropped_image)\n",
    "\n",
    "        if (result!=[]):\n",
    "            return result\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pic :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[19, 9], [39, 9], [39, 33], [19, 33]], '2', 1.0)] pic :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[68, 6], [104, 6], [104, 34], [68, 34]], '15', 0.9767927827200859)] pic :  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[67, 5], [85, 5], [85, 29], [67, 29]], '3', 0.999999046325911)] pic :  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] path :  D:\\coding\\projectm5\\data\\1-1\\1-1-drawing_page-0004.jpg\n",
      "pic :  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[66, 4], [102, 4], [102, 33], [66, 33]], '27', 1.0)] pic :  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[22, 8], [60, 8], [60, 36], [22, 36]], '13', 0.9999988198884456)] pic :  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# jpg_file = open(jpg_file_path, \"r\")\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdetectID\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjpg_file_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(result, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m original_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mstr\u001b[39m(jpg_file_path))\n",
      "Cell \u001b[1;32mIn[29], line 32\u001b[0m, in \u001b[0;36mdetectID\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m     (x2, y2) \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mmax(x), np\u001b[38;5;241m.\u001b[39mmax(y))\n\u001b[0;32m     30\u001b[0m     cropped_image \u001b[38;5;241m=\u001b[39m gray[x1:x2\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, y1:y2\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 32\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43measyocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     result \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mreadtext(cropped_image)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (result\u001b[38;5;241m!=\u001b[39m[]):\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\easyocr\\easyocr.py:214\u001b[0m, in \u001b[0;36mReader.__init__\u001b[1;34m(self, lang_list, gpu, model_storage_directory, user_network_directory, detect_network, recog_network, download_enabled, detector, recognizer, verbose, quantize, cudnn_benchmark)\u001b[0m\n\u001b[0;32m    211\u001b[0m     dict_list[lang] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict\u001b[39m\u001b[38;5;124m'\u001b[39m, lang \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitDetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recognizer:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recog_network \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\easyocr\\easyocr.py:271\u001b[0m, in \u001b[0;36mReader.initDetector\u001b[1;34m(self, detector_path)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitDetector\u001b[39m(\u001b[38;5;28mself\u001b[39m, detector_path):\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mquantize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcudnn_benchmark\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn_benchmark\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\easyocr\\detection.py:75\u001b[0m, in \u001b[0;36mget_detector\u001b[1;34m(trained_model, device, quantize, cudnn_benchmark)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_detector\u001b[39m(trained_model, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, quantize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cudnn_benchmark\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 75\u001b[0m     net \u001b[38;5;241m=\u001b[39m \u001b[43mCRAFT\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     78\u001b[0m         net\u001b[38;5;241m.\u001b[39mload_state_dict(copyStateDict(torch\u001b[38;5;241m.\u001b[39mload(trained_model, map_location\u001b[38;5;241m=\u001b[39mdevice)))\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\easyocr\\craft.py:35\u001b[0m, in \u001b[0;36mCRAFT.__init__\u001b[1;34m(self, pretrained, freeze)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28msuper\u001b[39m(CRAFT, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Base network \"\"\"\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasenet \u001b[38;5;241m=\u001b[39m \u001b[43mvgg16_bn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreeze\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" U network \"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv1 \u001b[38;5;241m=\u001b[39m double_conv(\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\easyocr\\model\\modules.py:27\u001b[0m, in \u001b[0;36mvgg16_bn.__init__\u001b[1;34m(self, pretrained, freeze)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m(vgg16_bn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(torchvision\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.13\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 27\u001b[0m     vgg_pretrained_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg16_bn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVGG16_BN_Weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m#torchvision.__version__ < 0.13\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     models\u001b[38;5;241m.\u001b[39mvgg\u001b[38;5;241m.\u001b[39mmodel_urls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16_bn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mvgg\u001b[38;5;241m.\u001b[39mmodel_urls[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvgg16_bn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[0;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\vgg.py:459\u001b[0m, in \u001b[0;36mvgg16_bn\u001b[1;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"VGG-16-BN from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    :members:\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m weights \u001b[38;5;241m=\u001b[39m VGG16_BN_Weights\u001b[38;5;241m.\u001b[39mverify(weights)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\vgg.py:103\u001b[0m, in \u001b[0;36m_vgg\u001b[1;34m(cfg, batch_norm, weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m         _ovewrite_named_param(kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(weights\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m--> 103\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVGG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(weights\u001b[38;5;241m.\u001b[39mget_state_dict(progress\u001b[38;5;241m=\u001b[39mprogress, check_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\vgg.py:62\u001b[0m, in \u001b[0;36mVGG.__init__\u001b[1;34m(self, features, num_classes, init_weights, dropout)\u001b[0m\n\u001b[0;32m     60\u001b[0m     nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mconstant_(m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mLinear):\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mconstant_(m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\init.py:155\u001b[0m, in \u001b[0;36mnormal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(normal_, (tensor,), tensor\u001b[38;5;241m=\u001b[39mtensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd)\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_no_grad_normal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\init.py:19\u001b[0m, in \u001b[0;36m_no_grad_normal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_normal_\u001b[39m(tensor, mean, std):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for jpg_file_path in list(folder.rglob('*.jpg')):\n",
    "    # print(type(jpg_file_path))\n",
    "    print(\"pic : \", i)\n",
    "    i+=1\n",
    "    # jpg_file = open(jpg_file_path, \"r\")\n",
    "    result = detectID(str(jpg_file_path))\n",
    "    print(result, end=\" \")\n",
    "\n",
    "    original_img = cv2.imread(str(jpg_file_path))\n",
    "\n",
    "    if len(result) > 0:\n",
    "        Id = result[0][1].rjust(3, '0')\n",
    "        cv2.imwrite(f'data_label\\\\{Id}.jpg', original_img)\n",
    "    else:\n",
    "        print(\"path : \",jpg_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
